{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0f333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q -U pip\n",
    "!pip install -q torch==2.1.0a0+32f93b1\n",
    "!pip install -q transformers==4.43.3\n",
    "!pip install -q peft==0.12.0\n",
    "!pip install -q jinja2==3.1.4\n",
    "!pip install -q bitsandbytes==0.43.0\n",
    "!pip install -q datasets==2.20.0\n",
    "!pip install -q multiprocess==0.70.16\n",
    "!pip install -q accelerate==0.33.0\n",
    "!pip install -q trl==0.9.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a83cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ebfa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 경로 환경변수 설정\n",
    "!export LD_LIBRARY_PATH=\"~/.local/lib/python3.10/site-packages/:$LD_LIBRARY_PATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc45693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import os \n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce11c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.login('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b75e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 다운로드\n",
    "# from huggingface_hub import snapshot_download\n",
    "# snapshot_download(repo_id=\"MLP-KTLim/llama-3-Korean-Bllossom-8B\", local_dir = \"./models_llama-3-Korean-Bllossom-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177d6e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 로컬 디렉토리에서 토크나이저와 모델 로드\n",
    "model_id = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\"\n",
    "local_dir = \"./models_llama-3-Korean-Bllossom-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양자화 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_use_double_quant=False,\n",
    "    bnb_8bit_quant_type=\"int8\", \n",
    "    bnb_8bit_compute_dtype=torch.float16 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc868e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_dir,\n",
    "    quantization_config=bnb_config,  #양자화 적용\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac83dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습가능 파라미터 개수와 비율 표시\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ee9e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lora 학습용 변수 설정. 모델 구조에 따라 target_modules는 바꿔줘야 한다. \n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"self_attn.q_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"self_attn.o_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"mlp.down_proj\"\n",
    "    ],\n",
    "    lora_dropout=0.01,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# 모델에 lora를 적용한다. \n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 가중치 불러오기\n",
    "model.load_state_dict(torch.load(\"./con_trained\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a07f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 사용중인 device 확인\n",
    "#print(f\"Model is using device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6515cc45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 구조 확인\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name, type(module))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99161ad",
   "metadata": {},
   "source": [
    "# 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "당신은 OKR 문장 평가 전문가입니다.\n",
    "평가기준은 '연결성'입니다. 평가기준에 대한 설명을 보고, 이를 엄격히 준수해서 평가합니다.\n",
    "평가 기준에 따라 평가할 때, 상위목표, 기업명, 업종, 조직명을 반드시 참고해 주십시오.\n",
    "\n",
    "# 평가기준\n",
    "## 평가기준에 대한 설명\n",
    "연결성은 다음과 같은 두 가지 기준으로 평가합니다.\n",
    "기준 1. 상위목표를 달성하는 데 핵심결과가 기여하는가?\n",
    "기준 2. 핵심결과 문장이 나타내는 바가 구체적이고 명확한가?\n",
    "## 평가기준에 따른 점수\n",
    "평가기준에 대한 설명을 반드시 엄격히 준수합니다. 그리고 평가기준을 만족하는 정도에 따라 점수를 다르게 주세요.\n",
    "4~5점: 기준 1과 기준 2를 모두 만족한다.\n",
    "3~3.5점: 기준 1은 만족하지만, 기준 2는 만족하지 못한다.\n",
    "2~2.5점: 기준2는 만족하지만, 기준 1은 만족하지 못한다.\n",
    "1~1.5점: 기준 1과 기준 2를 모두 만족하지 못한다.\n",
    "\n",
    "# 출력\n",
    "출력은 반드시 아래와 같은 형식을 엄격히 지켜주세요.\n",
    "\n",
    "점수: [1부터 5사이의 점수, 소수점 단위 0.5]\n",
    "이유: [점수를 준 이유]\n",
    "\"\"\"\n",
    "\n",
    "input_template = \"\"\"\n",
    "상위목표 = {upper_objective}\n",
    "핵심결과 = {input_sentence}\n",
    "\"\"\"\n",
    "\n",
    "output_template = \"\"\"\n",
    "점수: {connectivity}\n",
    "이유: {connectivity_description}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7278eb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터셋 불러오기\n",
    "df = pd.read_csv('revision_240806_dataset_plus.csv')\n",
    "\n",
    "dfKeyresult = df[df[\"type\"] == \"Key Result\"]  # keyResult행만 추출\n",
    "dfKeyresult = dfKeyresult[['row_num', 'type', 'input_sentence', 'upper_objective', 'company', 'field', 'team', 'connectivity', 'connectivity_description', 'predict_connectivity', 'predict_connectivity_description']]  #특정 열만 추출\n",
    "dfKeyresult = dfKeyresult.dropna(subset=[\"input_sentence\", \"upper_objective\", \"connectivity\", \"connectivity_description\"])  #결측값 있는 행 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752695ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dfKeyresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a87fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 train, test 2가지 용도로 분할. random_state로 랜덤 시드를 지정한다. \n",
    "from sklearn.model_selection import train_test_split\n",
    "     \n",
    "train_df, test_df = train_test_split(dfKeyresult, test_size=0.1, random_state=100)\n",
    "\n",
    "#print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb190164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 원시 데이터프레임에 템플릿 적용하고 리스트로 변환\n",
    "def data2list(df):\n",
    "    input_conversations= []\n",
    "    for index, row in df.iterrows():\n",
    "        input_text = input_template.format(\n",
    "            upper_objective=row[\"upper_objective\"],\n",
    "            input_sentence=row[\"input_sentence\"]\n",
    "        )\n",
    "\n",
    "        output_text = output_template.format(\n",
    "            connectivity=row[\"connectivity\"],\n",
    "            connectivity_description=row[\"connectivity_description\"]\n",
    "        )\n",
    "        \n",
    "        input_conversation = { 'messages' : [{\"role\": \"system\", \"content\": f\"{system_prompt.strip()}\"},\n",
    "                                            {\"role\": \"user\", \"content\": f\"{input_text.strip()}\"},\n",
    "                                            {\"role\": \"assistant\", \"content\": f\"{output_text.strip()}\"}]\n",
    "        }\n",
    "        \n",
    "        input_conversation = {\"text\": tokenizer.apply_chat_template(input_conversation['messages'], tokenize=False)}\n",
    "        input_conversations.append(input_conversation)\n",
    "    \n",
    "    return input_conversations\n",
    "\n",
    "train_dataset = data2list(train_df)\n",
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "test_dataset = data2list(test_df)\n",
    "test_dataset = Dataset.from_list(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e2c3f",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "print(\"train mode on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec3521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 훈련 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStoppingCallback(early_stopping_patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4552daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 설정\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    dataset_text_field=\"text\",\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    #callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d4dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.delete_run('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78389c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "torch.save(model.state_dict(), \"./con_trained\")\n",
    "\n",
    "# model.save_pretrained(\"./trained_model\")\n",
    "# tokenizer.save_pretrained(\"./trained_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa18c3",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d392fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "        ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
    "    \n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,  # Add attention mask\n",
    "        max_new_tokens=2048,\n",
    "        eos_token_id=terminators,\n",
    "        pad_token_id=tokenizer.eos_token_id,  # Set pad token ID to eos token ID\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f259e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(text):\n",
    "    # 정규 표현식을 사용하여 상위목표, 핵심결과, 점수, 이유를 추출\n",
    "    upper_objective_match = re.search(r\"상위목표\\s*=\\s*(.*)\", text)\n",
    "    input_sentence_match = re.search(r\"핵심결과\\s*=\\s*(.*)\", text)\n",
    "    score_match = re.findall(r\"점수:\\s*([\\d.]+)\", text)\n",
    "    reason_match = re.findall(r\"이유:\\s*(.*)\", text)\n",
    "\n",
    "    # 추출된 결과\n",
    "    if upper_objective_match:\n",
    "        upper_objective = upper_objective_match.group(1).strip()\n",
    "\n",
    "    if input_sentence_match:\n",
    "        input_sentence = input_sentence_match.group(1).strip()\n",
    "\n",
    "    if score_match:\n",
    "        if len(score_match) > 1:\n",
    "            score = score_match[1].strip()\n",
    "        else:\n",
    "            score = score_match[0].strip()\n",
    "\n",
    "    if reason_match:\n",
    "        if len(reason_match) > 1:\n",
    "            reason = reason_match[1].strip()\n",
    "        else:\n",
    "            reason = reason_match[0].strip()\n",
    "    \n",
    "    return upper_objective, input_sentence, score, reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a136c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성 결과 저장용\n",
    "def extract_data2(text):\n",
    "    score_match = re.findall(r\"점수:\\s*([\\d.]+)\", text)\n",
    "    description_match = re.findall(r\"이유:\\s*(.*)\", text)\n",
    "\n",
    "    predict_score = score_match[0].strip() if score_match else None\n",
    "    predict_description = description_match[0].strip() if description_match else None\n",
    "\n",
    "    return predict_score, predict_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1afdfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train 데이터 평가\n",
    "print(\"[krEV]\")\n",
    "#start_index = int(input(\"enter start index: \"))\n",
    "for index, row in dfKeyresult.iterrows():\n",
    "    if pd.isna(dfKeyresult.loc[index, 'predict_connectivity']):\n",
    "        print(f\"idx : {index}\")\n",
    "\n",
    "        upper_objective, input_sentence, connectivity, connectivity_description = row[['upper_objective', 'input_sentence', 'connectivity', 'connectivity_description']]\n",
    "        print(f\"상위목표: {upper_objective}\")\n",
    "        print(f\"핵심결과: {input_sentence}\")\n",
    "        print(\"<전문가>\")\n",
    "        print(f\"_점수: {connectivity}\")\n",
    "        print(f\"_이유: {connectivity_description}\")\n",
    "\n",
    "        input_text = input_template.format(upper_objective = upper_objective, input_sentence = input_sentence)\n",
    "        #print(text)\n",
    "        print()\n",
    "        print(\"<AI>\")\n",
    "\n",
    "        predict = generate(input_text)\n",
    "        print(predict)\n",
    "        print(type(predict))\n",
    "        predict_score, predict_description = extract_data2(predict)\n",
    "        print(f\"predict_score: {predict_score}\")\n",
    "        print(f\"predict_description: {predict_description}\")\n",
    "\n",
    "        dfKeyresult.loc[index, ['predict_connectivity', 'predict_connectivity_description']] = predict_score, predict_description\n",
    "\n",
    "        print('='*100)\n",
    "        print('='*100)\n",
    "        print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ea78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfKeyresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffa7ce3",
   "metadata": {},
   "source": [
    "# 모델 간단 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcae00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "당신은 OKR 문장 평가 전문가입니다. \n",
    "핵심결과 달성이 상위목표 실현에 얼마나 연결되어 있는지 점수(1-5)와 평가 이유를 구체적으로 제공하십시오.\n",
    "점수는 1은 거의 기여하지 않음, 5는 매우 기여함을 의미합니다. \n",
    "기업명, 업종, 조직명을 참고해 주십시오. \n",
    "반드시 아래의 출력 형식을 지키십시오.\n",
    "\n",
    "점수: [1-5 범위의 숫자]\n",
    "이유: [점수를 준 이유]\n",
    "\"\"\"\n",
    "\n",
    "ex_text = \"\"\"\n",
    "<입력>\n",
    "상위목표: 보다 많은 사람들이 서비스를 이용한다(고객의 양적 창출)\n",
    "핵심결과: 신규 사용자 수를 10만 명에서 100만 명으로 늘린다.\n",
    "</입력>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60024014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate(system_prompt, ex_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.1 (NGC 23.09/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
